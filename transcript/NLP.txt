What is natural? Language processing. Well, you're doing it right now. You're listening to the words and the sentences that I'm forming and you are forming some sort of comprehension from it. And when we ask a computer to do that, that is NLP, or Natural Language Processing. My name is Martin Keane. I'm a master inventor at IBM and I've utilized NLP in a good number of my invention. Disclosures NLP really has a really high utility value in all sorts of AI applications. Now, NLP starts with something called unstructured Text. What is that? Well, that's just what you and I say. That's how we speak. So for example, some unstructured text is add eggs and milk to my shopping list. Now, you and I understand exactly what that means, but it is unstructured, at least to a computer. So what we need to do is to have a structured representation of that same information that a computer can process. Now that might look something a bit more like this, where we have a shopping list element and then it has sub elements within it, like an item for eggs and an item for milk. That is an example of something that is structured. Now, the job of Natural Language Processing is to translate between these two things. So NLP sits right in the middle here translating between unstructured and structured data. And when we go from structured from unstructured here to structured this way, that's called NLU or Natural Language Understanding. And when we go this way from structured to unstructured, that's called Natural Language Generation or NLG. We're going to focus today primarily on going from unstructured to structured in Natural Language Processing. Now, let's think of some use cases where NLP might be quite handy. First of all, we've got machine translation. Now when we translate from one language to another, we need to understand the context of that sentence. It's not just a case of taking each individual word from, say, English and then translating it into another language. We need to understand the overall structure and context of what's being said. And my favorite example of this going horribly wrong is if you take the phrase, the spirit is willing, but the flesh is weak, and you translate that from English to Russian, and then you translate that Russian translation back. Into English, you're going to go from the spirit is willing, but the flesh is weak, to something a bit more like the vodka is good, but the meat is rotten, which is really not the intended context of that sentence whatsoever. So NLP can help with situations like that. Now, the second kind of use case that I like to mention relates to virtual assistants and also to things like chat bots. Now a virtual assistant, that's something like Siri or Alexa on your phone that is taking human utterances and deriving a command to execute based upon that. And a chatbot is something similar except in written language. And that's taking written language and then using it to traverse a decision tree in order to take an action. NLP is very helpful there. Another use case is for sentiment analysis. Now, this is taking some text, perhaps an email message or a product review, and trying to derive the sentiment that it's expressed within it. So, for example, is this product review a positive sentiment or a negative sentiment? Is it written as a serious statement or is it being sarcastic? We can use NLP to tell us. And then finally, another good example is spam detection. So this is a case of looking at a given email message and trying to drive, is this a real email message or is it spam? And we can look for pointers within the content of the message. So things like overused words or poor grammar or an inappropriate claim of urgency can all indicate that this is actually perhaps spam. So those are some of the things that NLP can provide. But how does it work? Well, the thing with NLP is it's not like one algorithm, it's actually more like a bag of tools. And you can apply these bag of tools to be able to resolve some of these use cases. Now, the input to NLP is some unstructured text. So either some written text or spoken text that has been converted to written text through a speech to text algorithm. Once we've got that, the first stage of NLP is called tokenization. This is about taking a string and breaking it down into chunks. So if we consider the unstructured text we've got here, add eggs and milk to my shopping list, that's eight words. That can be eight tokens. And from here on in, we are going to work one token at a time as we traverse through this. Now, the first stage, once we've got things down into tokens that we can perform, is called stemming. And this is all about deriving the word stem for a given token. So, for example, running runs and ran. The word stem for all three of those is run. We're just kind of removing the prefix and the suffixes and normalizing the tense and we're getting to the word stem. But stemming doesn't work well for every token. For example, Universal and University, well, they don't really stem down to universe for situations like that. There is another tool that we have available and that is called lematization. And lematization takes a given token and learns its meaning through a dictionary definition. And from there it can derive its root or its lem. So take better, for example. Better is derived from good. So the root or the lem of better is good. The stem of better would be bet. So you can see that it is significant whether we use stemming or we use Lamatization for a given token. Now, next thing we can do is we can do a process called part of speech tagging. And what this is doing is for a given token. It's looking where that token is used within the context of a sentence. So take the word make. For example, if I say I'm going to make dinner, make is a verb. But if I ask you what make is your laptop? Well, make is now a noun. So where that token is used in a sentence matters. Part of speech tagging can help us derive that context. And then finally another stage is named entity recognition. And what this is asking is for a given token, is there an entity associated with it? So for example, a token of Arizona has an entity of a US state, whereas a token of Ralph has an entity of a person's name. And these are some of the tools that we can apply in this big bag of tools that we have for NLP in order to get from this unstructured human speech through to something structured that a computer can understand. And once we've done that, then we can apply that structured data to all sorts of AI applications. Now there's obviously a lot more to it than this, and I've included some links in the description if you'd like to know more, but hopefully this made some sense and that you were able to process some of the natural language that I've shared today. Thanks for watching. If you have questions, please drop us a line below. And if you want to see more videos like this in the future, please like and subscribe.