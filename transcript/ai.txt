So with all this crazy time with nothing getting achieved, no success whatsoever and so on, we finally got our first success. And the first success was in 1996. An algorithm called EQP proved a theorem, which was always believed to be true as a conjecture. But we did not have a proof that was a mini success for AI. Because remember, the logic theorist had started way back in fifty s. And what is very interesting also is how the press reported it. So for example, New York Times said that an Argon lab program has come up with a major mathematical proof. So far so good. That would have been called creative if a human had thought of it. Notice the reluctance in calling the machine creative. Notice the reluctance in thinking of the machine as an intelligent being, not being or device or whatever. So this way of looking at the world stayed okay because in 1997, what was the main event I'm going to look at now? Somebody know? Success of AI in 1997? CNN Paper you guys are too narrow minded. You know, when was the first time CNN actually showed promise? 2012. We are in 1997. CNN may have been written just about then or in 99 or something, but that is you can't call it a success. Then what is the AI success in 97? Chess should look at your some history. Deep Blue, after so much time of claiming that we can defeat humans in chess, finally defeated the grandmaster Gary Kasparov. Now this particular comment from CNN is actually funny because Deep Blue's predecessor was called any guesses? Deep I can't hear you. Thought. So Deep thought was Deep Blue's predecessor and that was not able to defeat Gary Kaslov at the time. So therefore this title is funny. Deep Blue was seen as some cunning computer which is now quote unquote, killing humans in chess. Right. And there are many things I want to say about this. First thing is, of course, 1996, Deep Blue was a huge supercomputer for one move. All the supercomputer was running and evaluating and figuring out what is the right move. It was made by IBM. There was a competition in 96 which Gary Kasperv has defeated deeplow 42. So Gary Kasperv was very confident. Of course, IBM guys improved it and they had a rematch in 97 and Deep Blue won 3.5 to 2.5. It was a close match. It is gary Kasperv said that I could feel human level intelligence across the room. This you can say if your machine is terrible than humans, because at some point it is possible that machine overtakes humans. And then by saying that machine you have a human level intelligence is a bad complement. At the time, this was the first demonstration of the machine beating humans in chess. But now do we have a single human who can defeat the best machine in chess? No. In fact, in a few years, even a single victory in a long series of games would be a triumph of human genius. That human now has machine level intelligence in chess. And that is something that we will also work with. That intelligence is not a zero one phenomenon. There are degrees of intelligence. Now, many other interesting things happened, and we'll stop after this slide. It was questioned whether Deep Blue really uses AI or it's this one specific algorithm called the Heuristic search minimax algorithm with heuristic evaluation function. Is it really AI? And that was very complicated a question, because a lot of people thought that's not intelligence, that's just some search algorithm. And of course, any algorithm will be some algorithm. Whatever you put in as your intelligence algorithm will be some algorithm, right? And the human will say that's not intelligence, that's just algorithm X. So one of the senior researchers of AI, Drew McDermott at the time, responded by saying that saying Deep Blue doesn't really think about chess, it's not intelligent. About chess is like saying that an aeroplane doesn't fly because it doesn't flap its wings by getting the job done, right? Maybe a different way of getting the job done. It may not be intelligent like the way humans are intelligent, but it's still intelligent, right? And that led to the phenomenon, and it's a very famous sentence, if it works, it's not AI. We have to stop because we are out of time. So I will pick up from here tomorrow and we will discuss why do people say if it works, it's not AI. Why does AI, in principle never why does it never work? Kind of. Okay, so we'll talk about that starting tomorrow. Let's get started. So this is where we were after last class. We were talking about history of AI. We started talking about the fact that in some ways AI can be thought of as starting from Turing's paper, which asks, can machines think later? The AI as a field got developed and it went through various phases where sometimes AI was doing really well and bringing in a lot of money, bringing in a lot of energy. And then suddenly AI went down because of some reports of various other market forces playing into the picture. And AI had its winters. Until then, we had not really had a success story. And AI researchers were sort of started to getting branded as people who claim but don't deliver, right? And the one first change, as we talked about, happened when a theorem got proved, which was believed to be true by everybody, more or less, but there was no proof available, and a machine proved it. And then later, when, a year later, when Gary Caspero was actually defeated by IBM's Deep Blue in the game of chess, notice that chess itself had a long history of this prototypical intelligence application, because even in the olden days, there was a mechanical device which was playing chess. Do you know what it was called Mechanical Turk, and the people got really amazed as to what is happening and how is this machine playing chess so well. And then later it was found that there was a person hidden inside the big machine, and his height was quite short, so he could squeeze inside a small place, and that person was actually playing chess. Okay? And from there, the word Mechanical Turk came into the picture. And now you have heard of Mechanical Turk in a different context, which is Amazon's Mechanical Turk. The idea of crowdsourcing, we'll talk about that later at some point, maybe. So chess was this one application which was considered the intelligence application for many, many years. And ever since, very early in the 50s, they were saying, we will defeat humans in chess. Of course, that only happened 40 years later. And when this happened, once after this happened, there was a question of is Deep Blue really an AI system or is it like some brute force Ish search system which is just searching all possible plays and parts of gameplay and then making a decision on which is the best? And if so, is it really an AI system? And that led to the question that led to a very famous statement if it works, it's not AI. And let us think about this for the minute, because we as AI researchers, except for the last four or five years, have looked at this statement and sort of thought to each other, can we really succeed? Can AI ever work? Because as soon as something starts to work, they say, it's not AI. It's the algorithm X, whatever that algorithm be. And the more you think about it, the more you will start to observe why this happens. So let us go back 120 years, 140 years, and let us say we want to build an intelligent door, a door which has intelligence in it. What is this kind of a door? As soon as somebody wants to walk through, the door automatically opens. This is the thing of science fiction, maybe 120 years ago, that we will have this building where the doors will be so intelligent that they will remain closed, except when somebody wants to walk through, and then they will magically open up. Right? This feels like magical at the time. At the time you have to really go back. But now we know it's just a motion sensor. Now, as soon as I said it's just a motion sensor, I am taking this beauty full dream in your brain, in your mind, that the door will magically open. And I am creating a very real technology solution for it and saying, look, this is not that magical. It's just a sensor which operates in this way, this way, this way. Now, as soon as you see this, you will say, yeah, that's pretty awesome. I had this beautiful dream that doors will magically open. Now we know how to make that open and the next day will you feel the same kind of magic in Dose automatically opening because now you know how it works. So somebody said this very beautifully. They said that with deep understanding comes a deep sense of loss. And it'll take you some time to even over time in life to appreciate this, that there is something that works, something that you are amazed about how can they do it? And then suddenly you understand it. And once you understand it's just this algorithm that they are following. And once you know it, is that the algorithm that they are following, once you have understood it, it doesn't feel magical anymore. And your goal for life, if you are the person who is working on building intelligence, you say I thought this was my goal, but this we can do with this steps, no big deal. Let us work on that next thing which we can't do today. That is what is real intelligence. And so what keeps happening is that as you achieve a goalpost, your goalpost shifts and you feel like what you have achieved is no longer quote unquote, intelligence because it's just a very specific demonstration of it in this context and has a specific algorithm. But it's the next thing that you don't know what to do. That magic is still intact because you don't know what to do. So because of this constantly moving goalpost nature of intelligence and how we perceive intelligence, we started to say if it works, you know how it works. And if you know how it works, it's not intelligence anymore, it's not AI. The AI is the next thing that does not work. And so we have constantly grappled with this as AI researchers because as soon as we have a solution, the first time we have a solution, it's awesome. Then we look at the solution, whatever we'll move on. This also happens to you, by the way, when you learn a theorem. For example, let's say it's an unusual theorem your professor taught you very well, they gave you the proof, you were like wow, isn't that so cool? And a week down the line, what is it? It's just the sequence of steps that led you to this particular proof. You have now understood it. The sort of the beauty and the magic of it is sort of gone. And now it's the next theorem that you don't know how to solve. So this kind of phenomenon happens again and again. But in the field of AI, this sort of happened with the field itself. Because as soon as somebody said this is AI, they said no, this is algorithm X, that is AI, one that you don't know how to do. Therefore the sentence if it works, not AI. Which is also good because we'll always be in a job, whatever we do, we have not solved our problem. The problem is the next problem to. So we'll never be out of jobs.